{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aai2oA_LGH0u"
      },
      "source": [
        "# 1. Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rssabHOOGMCg"
      },
      "source": [
        "##a. Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "24TT6nMtDzlx",
        "outputId": "99dc349c-5f1b-4e5b-a9d8-b281931c090c"
      },
      "source": [
        "import keras \n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPARjOaBF97l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3237a1-0d3e-4556-974b-a148460f109b"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxTEjEmgGQYv",
        "outputId": "01b9acad-dd7e-42da-d0f4-953e69d6f7e9"
      },
      "source": [
        "print(train_X.shape, train_Y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfzAT1_nGfPD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "060ca429-bbe3-4a79-8b22-96ca1dfb894f"
      },
      "source": [
        "plt.figure()\n",
        "\n",
        "#subplot(r,c) provide the no. of rows and columns\n",
        "f, axarr = plt.subplots(2,2) \n",
        "\n",
        "axarr[0][0].imshow(train_X[0])\n",
        "axarr[0][1].imshow(train_X[1])\n",
        "axarr[1][0].imshow(train_X[2])\n",
        "axarr[1][1].imshow(train_X[3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f63a003eb50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLXUWGlOlf39"
      },
      "source": [
        "##b. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ4kEYWqjPC_",
        "outputId": "6a14e5b8-9c0f-49a1-a421-31a0ca79f784"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Model / data \n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "train_X = train_X.astype(\"float32\") / 255\n",
        "test_X = test_X.astype(\"float32\") / 255\n",
        "\n",
        "# Convert image shape to (28, 28, 1)\n",
        "train_X = np.expand_dims(train_X, -1)\n",
        "test_X = np.expand_dims(test_X, -1)\n",
        "\n",
        "print(\"train_X shape:\", train_X.shape)\n",
        "print(\"Training samples:\", train_X.shape[0])\n",
        "print(\"Test samples:\", test_Y.shape[0])\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "train_Y = to_categorical(train_Y, num_classes)\n",
        "test_Y = to_categorical(test_Y, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X shape: (60000, 28, 28, 1)\n",
            "Training samples: 60000\n",
            "Test samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSto7mqkvRE9"
      },
      "source": [
        "## c.Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eaPkuVjou08"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "def create_cnn( ):\n",
        "  # define using Sequential\n",
        "  model = Sequential()\n",
        "  # Convolution layer\n",
        "  model.add(\n",
        "      Conv2D(32, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Flatten output\n",
        "  model.add(Flatten())\n",
        "  # Dense layer of 100 neurons\n",
        "  model.add(\n",
        "      Dense (100,\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform') \n",
        "      )\n",
        "  model.add(Dense(10, activation='softmax')) # initialize optimizer\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  # compile model\n",
        "  model.compile(\n",
        "      optimizer=opt,\n",
        "      loss= 'categorical_crossentropy',\n",
        "      metrics =['accuracy']\n",
        "      )\n",
        "  print(model.layers)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqKScUtpqyGg",
        "outputId": "47b365fe-fa6d-478f-f1d7-90b8e16481d3"
      },
      "source": [
        "model = create_cnn()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<keras.layers.convolutional.Conv2D object at 0x7f639f7bddd0>, <keras.layers.pooling.MaxPooling2D object at 0x7f639f7bdb90>, <keras.layers.core.flatten.Flatten object at 0x7f639b6d5050>, <keras.layers.core.dense.Dense object at 0x7f639b6914d0>, <keras.layers.core.dense.Dense object at 0x7f639b73d410>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYkv2mXYwKtg"
      },
      "source": [
        "## d. Training and Evaluating the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLghwIiMu8-A",
        "outputId": "a5751611-1793-491f-c13e-b220c3c43707"
      },
      "source": [
        "model.fit(train_X, train_Y, batch_size=32, epochs=50, validation_split =0.1)\n",
        "score = model.evaluate(test_X, test_Y, verbose=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0881 - accuracy: 0.9741 - val_loss: 0.0631 - val_accuracy: 0.9847\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.0509 - val_accuracy: 0.9867\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.0456 - val_accuracy: 0.9875\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0468 - val_accuracy: 0.9890\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0465 - val_accuracy: 0.9888\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0500 - val_accuracy: 0.9883\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0527 - val_accuracy: 0.9867\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.0552 - val_accuracy: 0.9898\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0534 - val_accuracy: 0.9890\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0575 - val_accuracy: 0.9887\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0568 - val_accuracy: 0.9887\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0564 - val_accuracy: 0.9892\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 7.5779e-04 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9893\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.2065e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9892\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 5.0910e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9890\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 4.3360e-04 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9888\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 4.0139e-04 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9890\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 3.5794e-04 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9892\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.2551e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9890\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 2.9920e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9890\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 2.7473e-04 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9888\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 2.6459e-04 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9890\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 2.4190e-04 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9890\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 2.3002e-04 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9888\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 2.1481e-04 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9892\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 2.0404e-04 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9890\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.9128e-04 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9888\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.8385e-04 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9890\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 1.7406e-04 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9890\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 1.6707e-04 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9895\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 1.5906e-04 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9890\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 1.5319e-04 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9892\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.4580e-04 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9892\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.3869e-04 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9893\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.3544e-04 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9893\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.2982e-04 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9892\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.2579e-04 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9892\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.2073e-04 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9895\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.1738e-04 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9893\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.1322e-04 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9893\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.0932e-04 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9892\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.0619e-04 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9893\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.0302e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9893\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 1.0010e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9893\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 9.7020e-05 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9890\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 9.4119e-05 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9892\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 9.1857e-05 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9893\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 8.9414e-05 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9892\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 8.7271e-05 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9893\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 8.4909e-05 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm901tgp0KpX"
      },
      "source": [
        "## e. Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cd9U2uNwbqp",
        "outputId": "8bcc4fb6-1687-4f58-8932-6fc1f99ce946"
      },
      "source": [
        "epoch_history = model.fit(train_X, train_Y, batch_size=32, epochs=50, validation_split =0.1)\n",
        "\n",
        "# print validation and training accuracy over epochs\n",
        "print(epoch_history.history['accuracy']) \n",
        "print(epoch_history.history['val_accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 8.2730e-05 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9893\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 8.0604e-05 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9893\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 7.8886e-05 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9893\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 7.7298e-05 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9895\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 7.5534e-05 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9893\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 7.3595e-05 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9893\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 7.2128e-05 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9893\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 7.0304e-05 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9893\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 33s 20ms/step - loss: 6.9026e-05 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9893\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.7434e-05 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9893\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.6133e-05 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9895\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.4922e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9893\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.3548e-05 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9893\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.2274e-05 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9897\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.1082e-05 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9893\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 6.0101e-05 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9893\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.8868e-05 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9893\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.7684e-05 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9893\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.6763e-05 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9893\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.5732e-05 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9893\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.4706e-05 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9893\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.3810e-05 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9893\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.2918e-05 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9893\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.2007e-05 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9893\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.1206e-05 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9895\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 5.0237e-05 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9895\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.9446e-05 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9893\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.8693e-05 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9893\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.8042e-05 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9893\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 4.7228e-05 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9893\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 4.6562e-05 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9893\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 35s 21ms/step - loss: 4.5807e-05 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9893\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.5195e-05 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9893\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.4556e-05 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9893\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.3961e-05 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9893\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.3281e-05 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9893\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.2668e-05 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9893\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.2090e-05 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9893\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.1457e-05 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9893\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.0890e-05 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9893\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 4.0352e-05 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9893\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.9910e-05 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9893\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.9325e-05 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9893\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.8864e-05 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9893\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.8344e-05 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9893\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.7656e-05 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9893\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.7341e-05 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9893\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.6859e-05 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9895\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.6484e-05 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9893\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 34s 20ms/step - loss: 3.6080e-05 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9893\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "[0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9894999861717224, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9894999861717224, 0.9893333315849304, 0.9893333315849304, 0.9896666407585144, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9894999861717224, 0.9894999861717224, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9893333315849304, 0.9894999861717224, 0.9893333315849304, 0.9893333315849304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JZC2sVrh0b28",
        "outputId": "dbc4bcbf-99aa-45d9-f25b-266304a9b4fa"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(epoch_history.history['accuracy'])\n",
        "plt.plot(epoch_history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accutacy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT3idHNqzwSh"
      },
      "source": [
        "ii. Dropout layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZY2CLlw0blu"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "def create_cnn_with_dropout( ):\n",
        "  # define using Sequential\n",
        "  model = Sequential()\n",
        "  # Convolution layer\n",
        "  model.add(\n",
        "      Conv2D(32, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Flatten output\n",
        "  model.add(Flatten())\n",
        "  # Dropout Layer\n",
        "  model.add(Dropout(0.5)) \n",
        "  # Dense layer of 100 neurons\n",
        "  model.add(\n",
        "      Dense (100,\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform') \n",
        "      )\n",
        "  model.add(Dense(10, activation='softmax')) # initialize optimizer\n",
        "  opt = SGD(lr=0.01, momentum=0.9)\n",
        "  # compile model\n",
        "  model.compile(\n",
        "      optimizer=opt,\n",
        "      loss= 'categorical_crossentropy',\n",
        "      metrics =['accuracy']\n",
        "      )\n",
        "  \n",
        "  #print(model.layers)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27zf3gAx3vQj",
        "outputId": "56ebd7d5-3e2d-439f-9d62-02093f7e3074"
      },
      "source": [
        "new_model = create_cnn_with_dropout()\n",
        "\n",
        "new_model.fit(train_X, train_Y, batch_size=32, epochs=50, validation_split =0.1)\n",
        "score = new_model.evaluate(test_X, test_Y, verbose=0)\n",
        "dropout_history = new_model.fit(train_X, train_Y, batch_size=32, epochs=50, validation_split =0.1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 38s 22ms/step - loss: 0.2245 - accuracy: 0.9300 - val_loss: 0.0638 - val_accuracy: 0.9837\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0911 - accuracy: 0.9719 - val_loss: 0.0511 - val_accuracy: 0.9857\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0657 - accuracy: 0.9794 - val_loss: 0.0462 - val_accuracy: 0.9873\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.0415 - val_accuracy: 0.9885\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.0409 - val_accuracy: 0.9885\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0390 - val_accuracy: 0.9895\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.0407 - val_accuracy: 0.9895\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0427 - val_accuracy: 0.9890\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0413 - val_accuracy: 0.9897\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0402 - val_accuracy: 0.9893\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0457 - val_accuracy: 0.9882\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0391 - val_accuracy: 0.9903\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0427 - val_accuracy: 0.9902\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0450 - val_accuracy: 0.9897\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0450 - val_accuracy: 0.9898\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.0399 - val_accuracy: 0.9908\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0451 - val_accuracy: 0.9895\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0425 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0436 - val_accuracy: 0.9903\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0405 - val_accuracy: 0.9903\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0409 - val_accuracy: 0.9913\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0429 - val_accuracy: 0.9902\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0416 - val_accuracy: 0.9903\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0448 - val_accuracy: 0.9912\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0446 - val_accuracy: 0.9910\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.0467 - val_accuracy: 0.9908\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.0423 - val_accuracy: 0.9915\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0432 - val_accuracy: 0.9913\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0465 - val_accuracy: 0.9907\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0441 - val_accuracy: 0.9912\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0443 - val_accuracy: 0.9913\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0451 - val_accuracy: 0.9912\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0398 - val_accuracy: 0.9907\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0466 - val_accuracy: 0.9902\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0475 - val_accuracy: 0.9903\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0497 - val_accuracy: 0.9907\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0474 - val_accuracy: 0.9907\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0425 - val_accuracy: 0.9907\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0412 - val_accuracy: 0.9908\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0424 - val_accuracy: 0.9910\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0419 - val_accuracy: 0.9913\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0440 - val_accuracy: 0.9907\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0440 - val_accuracy: 0.9912\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0447 - val_accuracy: 0.9913\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0488 - val_accuracy: 0.9900\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0454 - val_accuracy: 0.9912\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0415 - val_accuracy: 0.9920\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0495 - val_accuracy: 0.9908\n",
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0431 - val_accuracy: 0.9918\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0430 - val_accuracy: 0.9918\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0482 - val_accuracy: 0.9917\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0459 - val_accuracy: 0.9910\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0463 - val_accuracy: 0.9913\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0479 - val_accuracy: 0.9913\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0496 - val_accuracy: 0.9913\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0498 - val_accuracy: 0.9913\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0446 - val_accuracy: 0.9922\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0483 - val_accuracy: 0.9903\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0469 - val_accuracy: 0.9913\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0453 - val_accuracy: 0.9913\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0482 - val_accuracy: 0.9927\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0484 - val_accuracy: 0.9920\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0505 - val_accuracy: 0.9910\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0491 - val_accuracy: 0.9917\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0471 - val_accuracy: 0.9918\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0502 - val_accuracy: 0.9917\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0500 - val_accuracy: 0.9913\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0474 - val_accuracy: 0.9922\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0529 - val_accuracy: 0.9907\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0501 - val_accuracy: 0.9907\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0468 - val_accuracy: 0.9918\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0512 - val_accuracy: 0.9913\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0499 - val_accuracy: 0.9907\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0491 - val_accuracy: 0.9918\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0466 - val_accuracy: 0.9917\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0484 - val_accuracy: 0.9917\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0544 - val_accuracy: 0.9910\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0461 - val_accuracy: 0.9915\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0474 - val_accuracy: 0.9913\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0510 - val_accuracy: 0.9913\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0561 - val_accuracy: 0.9913\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0546 - val_accuracy: 0.9910\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0534 - val_accuracy: 0.9910\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0502 - val_accuracy: 0.9922\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0572 - val_accuracy: 0.9907\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0548 - val_accuracy: 0.9907\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0548 - val_accuracy: 0.9903\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0517 - val_accuracy: 0.9907\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0518 - val_accuracy: 0.9915\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0539 - val_accuracy: 0.9918\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0523 - val_accuracy: 0.9912\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 36s 21ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0548 - val_accuracy: 0.9913\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0553 - val_accuracy: 0.9920\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0539 - val_accuracy: 0.9912\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0515 - val_accuracy: 0.9918\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0543 - val_accuracy: 0.9925\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 36s 22ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0517 - val_accuracy: 0.9925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zMnedTgz84pm",
        "outputId": "6bef73c8-4e23-45dd-fba4-7c7634b8e7f5"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(dropout_history.history['accuracy'])\n",
        "plt.plot(dropout_history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEKSRoVM9yyL"
      },
      "source": [
        "iii. CNN with extra layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ9-E-Oc4EQV"
      },
      "source": [
        "\n",
        "def create_cnn_with_layers( ):\n",
        "  # define using Sequential\n",
        "  model = Sequential()\n",
        "  # Convolution layer 1\n",
        "  model.add(\n",
        "      Conv2D(64, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer 1\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Convolution Layer 2\n",
        "  model.add(\n",
        "      Conv2D(32, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer 2\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Flatten output\n",
        "  model.add(Flatten())\n",
        "  # Dropout Layer\n",
        "  model.add(Dropout(0.5)) \n",
        "  # Dense layer of 100 neurons\n",
        "  model.add(\n",
        "      Dense (100,\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform') \n",
        "      )\n",
        "  model.add(Dense(10, activation='softmax')) # initialize optimizer\n",
        "  opt = SGD(lr=0.01, momentum=0.9)\n",
        "  # compile model\n",
        "  model.compile(\n",
        "      optimizer=opt,\n",
        "      loss= 'categorical_crossentropy',\n",
        "      metrics =['accuracy']\n",
        "      )\n",
        "  \n",
        "  #print(model.layers)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zz8lecw-kHo",
        "outputId": "16d4488f-b687-4b0c-e4e8-3f9f4f68c992"
      },
      "source": [
        "# Training the new CNN\n",
        "\n",
        "mult_layered_model = create_cnn_with_layers()\n",
        "\n",
        "new_model.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split =0.1)\n",
        "score = mult_layered_model.evaluate(test_X, test_Y, verbose=0)\n",
        "dropout_history = mult_layered_model.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split =0.1)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "   3/1688 [..............................] - ETA: 48s - loss: 2.7154e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1688/1688 [==============================] - 38s 22ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0539 - val_accuracy: 0.9918\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0534 - val_accuracy: 0.9915\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0578 - val_accuracy: 0.9908\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0510 - val_accuracy: 0.9917\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 38s 22ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0501 - val_accuracy: 0.9920\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 38s 22ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0488 - val_accuracy: 0.9917\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0488 - val_accuracy: 0.9922\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0522 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 38s 22ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0495 - val_accuracy: 0.9922\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 37s 22ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0528 - val_accuracy: 0.9922\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.2731 - accuracy: 0.9137 - val_loss: 0.0553 - val_accuracy: 0.9835\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 0.1217 - accuracy: 0.9614 - val_loss: 0.0472 - val_accuracy: 0.9855\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 0.0947 - accuracy: 0.9701 - val_loss: 0.0359 - val_accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0817 - accuracy: 0.9742 - val_loss: 0.0381 - val_accuracy: 0.9882\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0692 - accuracy: 0.9779 - val_loss: 0.0323 - val_accuracy: 0.9903\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.0316 - val_accuracy: 0.9903\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.0579 - accuracy: 0.9818 - val_loss: 0.0329 - val_accuracy: 0.9905\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 69s 41ms/step - loss: 0.0527 - accuracy: 0.9828 - val_loss: 0.0294 - val_accuracy: 0.9908\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 68s 41ms/step - loss: 0.0501 - accuracy: 0.9839 - val_loss: 0.0273 - val_accuracy: 0.9918\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 0.0267 - val_accuracy: 0.9915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DVayfUaAzSZ"
      },
      "source": [
        "iv. Experimentation with different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIehM6HCA6S-"
      },
      "source": [
        "\n",
        "def final_create_cnn( ):\n",
        "  # define using Sequential\n",
        "  model = Sequential()\n",
        "  # Convolution layer 1\n",
        "  model.add(\n",
        "      Conv2D(64, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer 1\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Convolution Layer 2\n",
        "  model.add(\n",
        "      Conv2D(32, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer 2\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Flatten output\n",
        "  model.add(Flatten())\n",
        "  # Dropout Layer\n",
        "  model.add(Dropout(0.5)) \n",
        "  # Dense layer of 100 neurons\n",
        "  model.add(\n",
        "      Dense (100,\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform') \n",
        "      )\n",
        "  model.add(Dense(10, activation='softmax')) # initialize optimizer\n",
        "  opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "  # compile model\n",
        "  model.compile(\n",
        "      optimizer=opt,\n",
        "      loss= 'categorical_crossentropy',\n",
        "      metrics =['accuracy']\n",
        "      )\n",
        "  \n",
        "\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoWdiPMnH0c5",
        "outputId": "d2982683-4b21-40b3-b48c-d89daa097465"
      },
      "source": [
        "# Training the new CNN\n",
        "\n",
        "model1 = final_create_cnn()\n",
        "\n",
        "model1.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split =0.1)\n",
        "score = model1.evaluate(test_X, test_Y, verbose=0)\n",
        "history1 = model1.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split =0.1)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.4692 - accuracy: 0.8499 - val_loss: 0.1064 - val_accuracy: 0.9692\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.1875 - accuracy: 0.9418 - val_loss: 0.0761 - val_accuracy: 0.9780\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.1479 - accuracy: 0.9549 - val_loss: 0.0634 - val_accuracy: 0.9812\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 0.1269 - accuracy: 0.9609 - val_loss: 0.0577 - val_accuracy: 0.9847\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.1140 - accuracy: 0.9646 - val_loss: 0.0531 - val_accuracy: 0.9860\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 69s 41ms/step - loss: 0.1036 - accuracy: 0.9672 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 69s 41ms/step - loss: 0.0949 - accuracy: 0.9713 - val_loss: 0.0477 - val_accuracy: 0.9872\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 69s 41ms/step - loss: 0.0889 - accuracy: 0.9723 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0848 - accuracy: 0.9734 - val_loss: 0.0397 - val_accuracy: 0.9892\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0795 - accuracy: 0.9751 - val_loss: 0.0409 - val_accuracy: 0.9887\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0768 - accuracy: 0.9759 - val_loss: 0.0371 - val_accuracy: 0.9903\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.0385 - val_accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0706 - accuracy: 0.9772 - val_loss: 0.0380 - val_accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0688 - accuracy: 0.9782 - val_loss: 0.0371 - val_accuracy: 0.9885\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0669 - accuracy: 0.9791 - val_loss: 0.0356 - val_accuracy: 0.9898\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0641 - accuracy: 0.9797 - val_loss: 0.0350 - val_accuracy: 0.9897\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.0347 - val_accuracy: 0.9907\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 0.0390 - val_accuracy: 0.9892\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0585 - accuracy: 0.9819 - val_loss: 0.0357 - val_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.0329 - val_accuracy: 0.9910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op9JhicsICQk"
      },
      "source": [
        "\n",
        "def final_create_cnn( ):\n",
        "  # define using Sequential\n",
        "  model = Sequential()\n",
        "  # Convolution layer 1\n",
        "  model.add(\n",
        "      Conv2D(64, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer 1\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Convolution Layer 2\n",
        "  model.add(\n",
        "      Conv2D(32, (3, 3),\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform',\n",
        "      input_shape=(28, 28, 1))\n",
        "      )\n",
        "  # Maxpooling layer 2\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # Flatten output\n",
        "  model.add(Flatten())\n",
        "  # Dropout Layer\n",
        "  model.add(Dropout(0.5)) \n",
        "  # Dense layer of 100 neurons\n",
        "  model.add(\n",
        "      Dense (100,\n",
        "      activation= 'relu',\n",
        "      kernel_initializer='he_uniform') \n",
        "      )\n",
        "  model.add(Dense(10, activation='softmax')) # initialize optimizer\n",
        "  opt = SGD(learning_rate=0.1, momentum=0.9)\n",
        "  # compile model\n",
        "  model.compile(\n",
        "      optimizer=opt,\n",
        "      loss= 'categorical_crossentropy',\n",
        "      metrics =['accuracy']\n",
        "      )\n",
        "  \n",
        "\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdUeekeXIHfI",
        "outputId": "193d1a80-ce4c-4a3c-a37f-aed1e2700d05"
      },
      "source": [
        "# Training the new CNN\n",
        "\n",
        "model2 = final_create_cnn()\n",
        "\n",
        "model2.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split =0.1)\n",
        "score = model2.evaluate(test_X, test_Y, verbose=0)\n",
        "history2 = model2.fit(train_X, train_Y, batch_size=32, epochs=10, validation_split =0.1)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 1.0745 - accuracy: 0.6936 - val_loss: 1.1743 - val_accuracy: 0.6415\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 1.3197 - accuracy: 0.6063 - val_loss: 0.9009 - val_accuracy: 0.7183\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 65s 39ms/step - loss: 1.4983 - accuracy: 0.5166 - val_loss: 1.0165 - val_accuracy: 0.6652\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 1.5875 - accuracy: 0.4621 - val_loss: 1.2858 - val_accuracy: 0.5953\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 2.0825 - accuracy: 0.2509 - val_loss: 2.3082 - val_accuracy: 0.0992\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 2.3095 - accuracy: 0.1035 - val_loss: 2.3107 - val_accuracy: 0.0952\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 2.3080 - accuracy: 0.1044 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 2.3085 - accuracy: 0.1043 - val_loss: 2.3062 - val_accuracy: 0.1113\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 66s 39ms/step - loss: 2.3089 - accuracy: 0.1049 - val_loss: 2.3081 - val_accuracy: 0.1045\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3088 - accuracy: 0.1044 - val_loss: 2.3101 - val_accuracy: 0.1050\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3083 - accuracy: 0.1059 - val_loss: 2.3061 - val_accuracy: 0.1113\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 2.3091 - accuracy: 0.1036 - val_loss: 2.3088 - val_accuracy: 0.0960\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3085 - accuracy: 0.1028 - val_loss: 2.3106 - val_accuracy: 0.0960\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3079 - accuracy: 0.1044 - val_loss: 2.3066 - val_accuracy: 0.0960\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3081 - accuracy: 0.1040 - val_loss: 2.3068 - val_accuracy: 0.1050\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 2.3086 - accuracy: 0.1046 - val_loss: 2.3078 - val_accuracy: 0.1113\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3081 - accuracy: 0.1043 - val_loss: 2.3112 - val_accuracy: 0.0952\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3084 - accuracy: 0.1042 - val_loss: 2.3089 - val_accuracy: 0.0960\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 68s 40ms/step - loss: 2.3085 - accuracy: 0.1032 - val_loss: 2.3090 - val_accuracy: 0.1113\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 67s 40ms/step - loss: 2.3085 - accuracy: 0.1044 - val_loss: 2.3070 - val_accuracy: 0.1113\n"
          ]
        }
      ]
    }
  ]
}